{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rwxrwxrwx   1 jovyan supergroup   76861985 2018-08-01 17:15 /data/wiki/en_articles_part/articles-part\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /data/wiki/en_articles_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\r\n",
      "about\r\n",
      "above\r\n",
      "across\r\n",
      "after\r\n",
      "afterwards\r\n",
      "again\r\n",
      "against\r\n",
      "all\r\n",
      "almost\r\n",
      "alone\r\n",
      "along\r\n",
      "already\r\n",
      "also\r\n",
      "although\r\n",
      "always\r\n",
      "am\r\n",
      "among\r\n",
      "amongst\r\n",
      "amoungst\r\n",
      "amount\r\n",
      "an\r\n",
      "and\r\n",
      "another\r\n",
      "any\r\n",
      "anyhow\r\n",
      "anyone\r\n",
      "anything\r\n",
      "anyway\r\n",
      "anywhere\r\n",
      "are\r\n",
      "around\r\n",
      "as\r\n",
      "at\r\n",
      "back\r\n",
      "be\r\n",
      "became\r\n",
      "because\r\n",
      "become\r\n",
      "becomes\r\n",
      "becoming\r\n",
      "been\r\n",
      "before\r\n",
      "beforehand\r\n",
      "behind\r\n",
      "being\r\n",
      "below\r\n",
      "beside\r\n",
      "besides\r\n",
      "between\r\n",
      "beyond\r\n",
      "bill\r\n",
      "both\r\n",
      "bottom\r\n",
      "but\r\n",
      "by\r\n",
      "call\r\n",
      "can\r\n",
      "cannot\r\n",
      "cant\r\n",
      "co\r\n",
      "computer\r\n",
      "con\r\n",
      "could\r\n",
      "couldnt\r\n",
      "cry\r\n",
      "de\r\n",
      "describe\r\n",
      "detail\r\n",
      "do\r\n",
      "done\r\n",
      "down\r\n",
      "due\r\n",
      "during\r\n",
      "each\r\n",
      "eg\r\n",
      "eight\r\n",
      "either\r\n",
      "eleven\r\n",
      "else\r\n",
      "elsewhere\r\n",
      "empty\r\n",
      "enough\r\n",
      "etc\r\n",
      "even\r\n",
      "ever\r\n",
      "every\r\n",
      "everyone\r\n",
      "everything\r\n",
      "everywhere\r\n",
      "except\r\n",
      "few\r\n",
      "fifteen\r\n",
      "fify\r\n",
      "fill\r\n",
      "find\r\n",
      "fire\r\n",
      "first\r\n",
      "five\r\n",
      "for\r\n",
      "former\r\n",
      "formerly\r\n",
      "forty\r\n",
      "found\r\n",
      "four\r\n",
      "from\r\n",
      "front\r\n",
      "full\r\n",
      "further\r\n",
      "get\r\n",
      "give\r\n",
      "go\r\n",
      "had\r\n",
      "has\r\n",
      "hasnt\r\n",
      "have\r\n",
      "he\r\n",
      "hence\r\n",
      "her\r\n",
      "here\r\n",
      "hereafter\r\n",
      "hereby\r\n",
      "herein\r\n",
      "hereupon\r\n",
      "hers\r\n",
      "herse\"\r\n",
      "him\r\n",
      "himse\"\r\n",
      "his\r\n",
      "how\r\n",
      "however\r\n",
      "hundred\r\n",
      "i\r\n",
      "ie\r\n",
      "if\r\n",
      "in\r\n",
      "inc\r\n",
      "indeed\r\n",
      "interest\r\n",
      "into\r\n",
      "is\r\n",
      "it\r\n",
      "its\r\n",
      "itse\"\r\n",
      "keep\r\n",
      "last\r\n",
      "latter\r\n",
      "latterly\r\n",
      "least\r\n",
      "less\r\n",
      "ltd\r\n",
      "made\r\n",
      "many\r\n",
      "may\r\n",
      "me\r\n",
      "meanwhile\r\n",
      "might\r\n",
      "mill\r\n",
      "mine\r\n",
      "more\r\n",
      "moreover\r\n",
      "most\r\n",
      "mostly\r\n",
      "move\r\n",
      "much\r\n",
      "must\r\n",
      "my\r\n",
      "myse\"\r\n",
      "name\r\n",
      "namely\r\n",
      "neither\r\n",
      "never\r\n",
      "nevertheless\r\n",
      "next\r\n",
      "nine\r\n",
      "no\r\n",
      "nobody\r\n",
      "none\r\n",
      "noone\r\n",
      "nor\r\n",
      "not\r\n",
      "nothing\r\n",
      "now\r\n",
      "nowhere\r\n",
      "of\r\n",
      "off\r\n",
      "often\r\n",
      "on\r\n",
      "once\r\n",
      "one\r\n",
      "only\r\n",
      "onto\r\n",
      "or\r\n",
      "other\r\n",
      "others\r\n",
      "otherwise\r\n",
      "our\r\n",
      "ours\r\n",
      "ourselves\r\n",
      "out\r\n",
      "over\r\n",
      "own\r\n",
      "part\r\n",
      "per\r\n",
      "perhaps\r\n",
      "please\r\n",
      "put\r\n",
      "rather\r\n",
      "re\r\n",
      "same\r\n",
      "see\r\n",
      "seem\r\n",
      "seemed\r\n",
      "seeming\r\n",
      "seems\r\n",
      "serious\r\n",
      "several\r\n",
      "she\r\n",
      "should\r\n",
      "show\r\n",
      "side\r\n",
      "since\r\n",
      "sincere\r\n",
      "six\r\n",
      "sixty\r\n",
      "so\r\n",
      "some\r\n",
      "somehow\r\n",
      "someone\r\n",
      "something\r\n",
      "sometime\r\n",
      "sometimes\r\n",
      "somewhere\r\n",
      "still\r\n",
      "such\r\n",
      "system\r\n",
      "take\r\n",
      "ten\r\n",
      "than\r\n",
      "that\r\n",
      "the\r\n",
      "their\r\n",
      "them\r\n",
      "themselves\r\n",
      "then\r\n",
      "thence\r\n",
      "there\r\n",
      "thereafter\r\n",
      "thereby\r\n",
      "therefore\r\n",
      "therein\r\n",
      "thereupon\r\n",
      "these\r\n",
      "they\r\n",
      "thick\r\n",
      "thin\r\n",
      "third\r\n",
      "this\r\n",
      "those\r\n",
      "though\r\n",
      "three\r\n",
      "through\r\n",
      "throughout\r\n",
      "thru\r\n",
      "thus\r\n",
      "to\r\n",
      "together\r\n",
      "too\r\n",
      "top\r\n",
      "toward\r\n",
      "towards\r\n",
      "twelve\r\n",
      "twenty\r\n",
      "two\r\n",
      "un\r\n",
      "under\r\n",
      "until\r\n",
      "up\r\n",
      "upon\r\n",
      "us\r\n",
      "very\r\n",
      "via\r\n",
      "was\r\n",
      "we\r\n",
      "well\r\n",
      "were\r\n",
      "what\r\n",
      "whatever\r\n",
      "when\r\n",
      "whence\r\n",
      "whenever\r\n",
      "where\r\n",
      "whereafter\r\n",
      "whereas\r\n",
      "whereby\r\n",
      "wherein\r\n",
      "whereupon\r\n",
      "wherever\r\n",
      "whether\r\n",
      "which\r\n",
      "while\r\n",
      "whither\r\n",
      "who\r\n",
      "whoever\r\n",
      "whole\r\n",
      "whom\r\n",
      "whose\r\n",
      "why\r\n",
      "will\r\n",
      "with\r\n",
      "within\r\n",
      "without\r\n",
      "would\r\n",
      "yet\r\n",
      "you\r\n",
      "your\r\n",
      "yours\r\n",
      "yourself\r\n",
      "yourselves\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /datasets/stop_words_en.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/user/bin/env python\n",
    "import sys\n",
    "from line in sys.stdin:\n",
    "    words = line.split()\n",
    "for word in words:\n",
    "    print('{0}\\t{1}'.format(word,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/user/bin/env python\n",
    "import sys\n",
    "\n",
    "curr_word = None\n",
    "curr_count = 0\n",
    "\n",
    "for line in sys.stdin:\n",
    "    word,count = line.split('\\t')\n",
    "    count = int(count)\n",
    "    if word == curr_word:\n",
    "        curr_count += count\n",
    "    else:\n",
    "        if curr_word:\n",
    "            print('{0}\\t{1}'.format(curr_word),curr_count)\n",
    "        curr_word = word\n",
    "        curr_count = count\n",
    "    if curr_word == word:\n",
    "        print('{0}\\t{1}'.format(curr_word),curr_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wordcount.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile wordcount.txt\n",
    "\n",
    "hello how are you ?\n",
    "where are you ?\n",
    "what are you doing for a living ?\n",
    "what experience are you packing up in this lifetime ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkWordCount.ipynb  StopWordsTask2.ipynb  wordcount.txt\r\n",
      "mapper.py\t      supervisord.log\t    WordsRatingTask1.ipynb\r\n",
      "README.md\t      supervisord.pid\r\n",
      "reducer.py\t      WordCountTask0.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmr: DEPRECATED: Please use '-rm -r' instead.\n",
      "Deleted /word\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -rmr /word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: `word': File exists\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -mkdir word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -mv wordcount.txt word/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "hello how are you ?\r\n",
      "where are you ?\r\n",
      "what are you doing for a living ?\r\n",
      "what experience are you packing up in this lifetime ?"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat word/wordcount.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19/03/07 13:12:25 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "19/03/07 13:12:25 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "19/03/07 13:12:27 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "19/03/07 13:12:27 WARN hdfs.DataStreamer: Caught exception\n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:927)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:578)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:755)\n",
      "19/03/07 13:12:27 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "19/03/07 13:12:27 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1551938777455_0009\n",
      "19/03/07 13:12:28 INFO impl.YarnClientImpl: Submitted application application_1551938777455_0009\n",
      "19/03/07 13:12:28 INFO mapreduce.Job: The url to track the job: http://577b89c49055:8088/proxy/application_1551938777455_0009/\n",
      "19/03/07 13:12:28 INFO mapreduce.Job: Running job: job_1551938777455_0009\n",
      "19/03/07 13:12:42 INFO mapreduce.Job: Job job_1551938777455_0009 running in uber mode : false\n",
      "19/03/07 13:12:42 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "19/03/07 13:12:56 INFO mapreduce.Job: Task Id : attempt_1551938777455_0009_m_000000_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:175)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:169)\n",
      "\n",
      "19/03/07 13:12:56 INFO mapreduce.Job: Task Id : attempt_1551938777455_0009_m_000001_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:175)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:169)\n",
      "\n",
      "19/03/07 13:13:11 INFO mapreduce.Job: Task Id : attempt_1551938777455_0009_m_000001_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:175)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:169)\n",
      "\n",
      "19/03/07 13:13:11 INFO mapreduce.Job: Task Id : attempt_1551938777455_0009_m_000000_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:175)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:169)\n",
      "\n",
      "19/03/07 13:13:28 INFO mapreduce.Job: Task Id : attempt_1551938777455_0009_m_000001_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:175)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:169)\n",
      "\n",
      "19/03/07 13:13:28 INFO mapreduce.Job: Task Id : attempt_1551938777455_0009_m_000000_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:175)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:169)\n",
      "\n",
      "19/03/07 13:13:42 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "19/03/07 13:13:43 INFO mapreduce.Job: Job job_1551938777455_0009 failed with state FAILED due to: Task failed task_1551938777455_0009_m_000001\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "19/03/07 13:13:43 INFO mapreduce.Job: Counters: 17\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=7\n",
      "\t\tKilled map tasks=1\n",
      "\t\tKilled reduce tasks=1\n",
      "\t\tLaunched map tasks=8\n",
      "\t\tOther local map tasks=6\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=102549\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=102549\n",
      "\t\tTotal time spent by all reduce tasks (ms)=0\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=102549\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=0\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=105010176\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "19/03/07 13:13:43 ERROR streaming.StreamJob: Job not successful!\n",
      "Streaming Command Failed!\n",
      "cat: `wordcount1_1551964340595380/part-00000': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "OUT_DIR=\"wordcount1_\"$(date +\"%s%6N\")\n",
    "NUM_REDUCERS=1\n",
    "\n",
    "yarn jar /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/hadoop-streaming.jar \\\n",
    "    -D mapred.jab.name=\"wordCount\" \\\n",
    "    -D mapreduce.job.reduces=${NUM_REDUCERS} \\\n",
    "    -files mapper.py,reducer.py \\\n",
    "    -mapper \"python mapper.py\" \\\n",
    "    -combiner \"python reducer.py\" \\\n",
    "    -reducer \"python reducer.py\" \\\n",
    "    -input word/ \\\n",
    "    -output ${OUT_DIR} > /dev/null\n",
    "\n",
    "hdfs dfs -cat ${OUT_DIR}/part-00000  | head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
